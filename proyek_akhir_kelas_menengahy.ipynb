{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13PWUIcbEZMl"
      },
      "source": [
        "[link dataset](https://www.kaggle.com/datasets/doctrinek/oxford-iiit-cats-extended-10k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw3Y-QkNUkmC"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmRClWc1UmkC"
      },
      "source": [
        "### command line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qiL9QNgOkxl",
        "outputId": "f3d35cfd-57e3-4f51-8a77-d0b6a6b0ef66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n",
            "Downloading oxford-iiit-cats-extended-10k.zip to /content\n",
            "100% 992M/993M [00:50<00:00, 23.5MB/s]\n",
            "100% 993M/993M [00:50<00:00, 20.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "# import the kaggle.json from kaggle API into colab\n",
        "# do this command\n",
        "\n",
        "# install kaggle library\n",
        "!pip install kaggle\n",
        "# make a directory named .kaggle\n",
        "!mkdir ~/.kaggle\n",
        "# copy the kaggle.json into this new directory\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "# alocate the required permission for this file\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# download dataset\n",
        "!kaggle datasets download doctrinek/oxford-iiit-cats-extended-10k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iatjpnfERvgp",
        "outputId": "7a305f9f-6306-4e90-f675-949bee160b07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install split-folders\n",
        "!pip install pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl2qA-FeUqFO"
      },
      "source": [
        "### import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DWDLzxfvQCIp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib, zipfile, os, splitfolders, datetime\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a0xSKajycEp"
      },
      "source": [
        "### setup tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U-PeImB-yZFS"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-D-hnMsxybIC"
      },
      "outputs": [],
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_cq8qzcpyrUW"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YYmR1mIyucH",
        "outputId": "aef22877-bffd-4667-eb75-ca29cf0253cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.ops.summary_ops_v2._ResourceSummaryWriter at 0x7d0c398897e0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tf.summary.create_file_writer(\"./logs/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wnbm5kPDyz77"
      },
      "outputs": [],
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4XL8l8NUumI"
      },
      "source": [
        "### extract zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_-WcsYp3RqH2"
      },
      "outputs": [],
      "source": [
        "zip_path = \"/content/oxford-iiit-cats-extended-10k.zip\"\n",
        "zip_read = zipfile.ZipFile(zip_path, \"r\")\n",
        "zip_read.extractall('/content/dataset')\n",
        "zip_read.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNMdYQvPSXqi",
        "outputId": "eef09b8d-b13b-42e6-83e3-965d59dc3d85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CatBreedsRefined-v3']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "os.listdir('/content/dataset/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okAlXufi-V4j"
      },
      "source": [
        "### resize all the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRjFATa8UygV"
      },
      "source": [
        "### split into train and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "c2ykm44v_qLs"
      },
      "outputs": [],
      "source": [
        "original_dir = '/content/dataset/CatBreedsRefined-v3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcgN9EGxSeCG",
        "outputId": "2be39357-c2f4-41f3-d8a3-b11f06b4f72a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 10257 files [00:03, 2624.65 files/s]\n"
          ]
        }
      ],
      "source": [
        "splitfolders.ratio(original_dir, output='/content/dataset/project', seed=6969, ratio=(0.8, 0.2))\n",
        "train_dir = '/content/dataset/project/train'\n",
        "validation_dir = '/content/dataset/project/val'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dWMxNUWXp-A"
      },
      "source": [
        "### explore data samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL3REqb8VNa3",
        "outputId": "52efef49-b7a1-4df0-8f15-748109311dc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The train directory has 8202 samples\n",
            "The validation directory has 2055 samples\n",
            "Which in total makes it 10257 samples\n"
          ]
        }
      ],
      "source": [
        "def total_sample(directory):\n",
        "  total = 0\n",
        "  for folder in os.listdir(directory):\n",
        "    folder_path = os.path.join(directory, folder)\n",
        "    total += len(os.listdir(folder_path))\n",
        "\n",
        "  return total\n",
        "\n",
        "train_sample_length = total_sample(train_dir)\n",
        "validation_sample_length = total_sample(validation_dir)\n",
        "print(f\"The train directory has {train_sample_length} samples\")\n",
        "print(f\"The validation directory has {validation_sample_length} samples\")\n",
        "print(f\"Which in total makes it {train_sample_length + validation_sample_length} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx8svLuTeDio"
      },
      "source": [
        "# Preprocess Data\n",
        "```\n",
        "rescale = 1.0/255,\n",
        "shear_range=0.2,\n",
        "zoom_range=0.2,\n",
        "width_shift_range=0.2,\n",
        "height_shift_range=0.2,\n",
        "channel_shift_range=0.2,\n",
        "horizontal_flip=True,\n",
        "fill_mode='nearest'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6WhbKkYVoFs",
        "outputId": "b11f07c2-0253-4bc0-b261-28654476302f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8202 images belonging to 12 classes.\n",
            "Found 2055 images belonging to 12 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 16\n",
        "target_size=(224,224)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1.0/255,\n",
        "    shear_range=0.2,\n",
        "    channel_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    class_mode='categorical',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    class_mode='categorical',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGiSf7mbov4"
      },
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3HAZws3dWmp"
      },
      "source": [
        "### callback function\n",
        "- stops when acc & val_acc is >= 92%\n",
        "- stops when acc / val_acc < max_acc for limit_acc epochs\n",
        "- stops when loss / val_loss > 0.75 for limit_loss epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dTm_OJcUdWA_"
      },
      "outputs": [],
      "source": [
        "class SantaiDuluGakSih(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, sabar_acc=10, sabar_loss=10):\n",
        "    super(SantaiDuluGakSih, self).__init__()\n",
        "    self.sabar_acc = sabar_acc\n",
        "    self.sabar_loss = sabar_loss\n",
        "    self.limit_acc = sabar_acc\n",
        "    self.limit_loss = sabar_loss\n",
        "    self.max_acc = 0\n",
        "    self.max_val_acc = 0\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    self.max_acc = logs.get('accuracy') if logs.get('accuracy') > self.max_acc else self.max_acc\n",
        "\n",
        "    self.max_val_acc = logs.get('val_accuracy') if logs.get('val_accuracy') > self.max_val_acc else self.max_val_acc\n",
        "\n",
        "    if logs.get('accuracy')>=self.max_acc and logs.get('val_accuracy')>=self.max_val_acc:\n",
        "      self.sabar_acc = self.limit_acc\n",
        "    else:\n",
        "      self.sabar_acc -= 1\n",
        "\n",
        "    if logs.get('loss')>0.75 or logs.get('val_loss')>0.75:\n",
        "      self.sabar_loss -= 1\n",
        "    else:\n",
        "      self.sabar_loss += 1\n",
        "\n",
        "    if self.sabar_acc == 0:\n",
        "      print(f\"The model accuracy has been below {self.max_acc} and {self.max_val_acc} for {self.limit_acc} epochs, Stopping training immediatly!!!\")\n",
        "      self.model.stop_training = True\n",
        "    elif self.sabar_loss == 0:\n",
        "      print(f\"The model loss has been above 75% for {self.limit_loss} epochs, Stopping training immediatly!!!\")\n",
        "      self.model.stop_training = True\n",
        "    elif self.max_acc >= 0.92 and self.max_val_acc >= 0.92:\n",
        "      print(f\"The model accuracy has reached 92%, stopping training\")\n",
        "      self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_YLW4GPdKtS"
      },
      "source": [
        "### transfer learning using MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9CM9F6hok2Ey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c8bcee-d311-4cf3-ff06-6d881598c07f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n",
            " tional)                                                         \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 7, 7, 1280)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 5, 5, 64)          737344    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 2, 2, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 12)                780       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3078348 (11.74 MB)\n",
            "Trainable params: 820364 (3.13 MB)\n",
            "Non-trainable params: 2257984 (8.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "# add mobile net as base layer\n",
        "pre_trained_model = MobileNetV2(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_tensor=Input(shape=(224,224,3))\n",
        ")\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "\"\"\"for layer in pre_trained_model.layers[-5:]:\n",
        "  layer.trainable = True\"\"\"\n",
        "\n",
        "model.add(pre_trained_model)\n",
        "\n",
        "# add custom layers\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_IkwdaHMoy6X"
      },
      "outputs": [],
      "source": [
        "int_lr = 1e-3\n",
        "#lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=int_lr, decay_steps=1000, decay_rate=0.9)\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=int_lr),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucMB_aTnpIa5",
        "outputId": "a5c80a37-36bb-447a-f2d8-43439e81a328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "513/513 - 173s - loss: 1.3786 - accuracy: 0.6218 - val_loss: 0.9295 - val_accuracy: 0.7348 - 173s/epoch - 338ms/step\n",
            "Epoch 2/30\n",
            "513/513 - 172s - loss: 0.8550 - accuracy: 0.7725 - val_loss: 0.7629 - val_accuracy: 0.7942 - 172s/epoch - 335ms/step\n",
            "Epoch 3/30\n",
            "513/513 - 173s - loss: 0.7342 - accuracy: 0.7972 - val_loss: 0.6982 - val_accuracy: 0.8102 - 173s/epoch - 338ms/step\n",
            "Epoch 4/30\n",
            "513/513 - 172s - loss: 0.6077 - accuracy: 0.8249 - val_loss: 0.6046 - val_accuracy: 0.8336 - 172s/epoch - 335ms/step\n",
            "Epoch 5/30\n",
            "513/513 - 169s - loss: 0.5572 - accuracy: 0.8454 - val_loss: 0.6705 - val_accuracy: 0.8234 - 169s/epoch - 329ms/step\n",
            "Epoch 6/30\n",
            "513/513 - 170s - loss: 0.5117 - accuracy: 0.8522 - val_loss: 0.6183 - val_accuracy: 0.8263 - 170s/epoch - 331ms/step\n",
            "Epoch 7/30\n",
            "513/513 - 167s - loss: 0.4767 - accuracy: 0.8659 - val_loss: 0.5807 - val_accuracy: 0.8375 - 167s/epoch - 325ms/step\n",
            "Epoch 8/30\n",
            "513/513 - 169s - loss: 0.4325 - accuracy: 0.8684 - val_loss: 0.5733 - val_accuracy: 0.8316 - 169s/epoch - 330ms/step\n",
            "Epoch 9/30\n",
            "513/513 - 169s - loss: 0.4170 - accuracy: 0.8815 - val_loss: 0.5608 - val_accuracy: 0.8355 - 169s/epoch - 330ms/step\n",
            "Epoch 10/30\n",
            "513/513 - 167s - loss: 0.4047 - accuracy: 0.8860 - val_loss: 0.5542 - val_accuracy: 0.8404 - 167s/epoch - 326ms/step\n",
            "Epoch 11/30\n",
            "513/513 - 167s - loss: 0.4054 - accuracy: 0.8820 - val_loss: 0.5740 - val_accuracy: 0.8389 - 167s/epoch - 325ms/step\n",
            "Epoch 12/30\n",
            "513/513 - 170s - loss: 0.3554 - accuracy: 0.8967 - val_loss: 0.5646 - val_accuracy: 0.8394 - 170s/epoch - 331ms/step\n",
            "Epoch 13/30\n",
            "513/513 - 166s - loss: 0.3582 - accuracy: 0.8960 - val_loss: 0.6197 - val_accuracy: 0.8248 - 166s/epoch - 324ms/step\n",
            "Epoch 14/30\n",
            "513/513 - 168s - loss: 0.3404 - accuracy: 0.9012 - val_loss: 0.5807 - val_accuracy: 0.8438 - 168s/epoch - 328ms/step\n",
            "Epoch 15/30\n",
            "513/513 - 173s - loss: 0.3204 - accuracy: 0.9070 - val_loss: 0.5803 - val_accuracy: 0.8360 - 173s/epoch - 337ms/step\n",
            "Epoch 16/30\n",
            "513/513 - 166s - loss: 0.3225 - accuracy: 0.9054 - val_loss: 0.6096 - val_accuracy: 0.8341 - 166s/epoch - 324ms/step\n",
            "Epoch 17/30\n",
            "513/513 - 171s - loss: 0.3129 - accuracy: 0.9104 - val_loss: 0.6157 - val_accuracy: 0.8389 - 171s/epoch - 332ms/step\n",
            "Epoch 18/30\n"
          ]
        }
      ],
      "source": [
        "berhenti_bang = SantaiDuluGakSih(sabar_acc=10, sabar_loss=10)\n",
        "modelku = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[berhenti_bang, tensorboard_callback],\n",
        "    verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGV4AzYhxix0"
      },
      "source": [
        "# Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQMS5ICNxoHF"
      },
      "source": [
        "### plot loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nX2b89Obn8JL"
      },
      "outputs": [],
      "source": [
        "# plot loss\n",
        "plt.plot(modelku.history['loss'])\n",
        "plt.plot(modelku.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# plot acc\n",
        "plt.plot(modelku.history['accuracy'])\n",
        "plt.plot(modelku.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0Dj5IxszEjv"
      },
      "source": [
        "### show tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlacXB4qzF60"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb0__Uks1Bx2"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfvqLlNL1DcN"
      },
      "outputs": [],
      "source": [
        "# menyimpan model dalam format saved model\n",
        "export_dir = 'saved_model/'\n",
        "tf.saved_model.save(model, export_dir)\n",
        "\n",
        "# convert SavedModel menjadi vegs.tflite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_file = pathlib.Path('vegs.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}